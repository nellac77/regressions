{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression\n",
    "\n",
    "The multiple linear regression is similar to the simple linear regression, in that it is described by a straight line; however, the difference is that it depends on more than a single feature:\n",
    "\n",
    "$\n",
    "y=b_{0}+b_{1}x_{1}+\\ldots+b_{n}x_{n},\n",
    "$\n",
    "\n",
    "where $n=1,2,\\ldots,n$.\n",
    "\n",
    "We will build a machine learning model that will find the best fit line given multiple features under the assumption that, within the data, we have:\n",
    "+ linearity\n",
    "+ homoscedasticity (all random variables in the vector have the same finite variance)\n",
    "+ multivariate normality\n",
    "+ independent of errors\n",
    "+ sans multicollinearity\n",
    "\n",
    "We will not go over ensuring the data has these properties as this is a toy box exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Business Understanding and The Data\n",
    "\n",
    "For this exercise we will explore a business problem with the 50 Startups dataset. We are given profit/loss statement for 50 comapnies and we are assuming that a VC firm has tasked us with looking into these companies and create a model that will help them determine which types of companies they should invest in. In our data set, Profit is the response variable that depends on R&D Spend, Administration, State, Marketing Spend, and State as features.\n",
    "\n",
    "The firm is not necessarily looking for which companies in this set to invest in; rather, they are looking for features they should consider based on this sample. Do companies in Florida perform better than those in California? Or does a company that invests more heavily in R&D turn more profit than one that invested heavily in marketing? They want to know how to assess companies. Where, and which, types of companies should they spend on?\n",
    "\n",
    "So, can we determine a linear dependency between all the features and the response, Profit?\n",
    "\n",
    "Let's start answering this by bringing in and inspecting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 5) \n",
      "    R&D Spend  Administration  Marketing Spend       State     Profit\n",
      "0  165349.20       136897.80        471784.10    New York  192261.83\n",
      "1  162597.70       151377.59        443898.53  California  191792.06\n",
      "2  153441.51       101145.55        407934.54     Florida  191050.39\n",
      "3  144372.41       118671.85        383199.62    New York  182901.99\n",
      "4  142107.34        91391.77        366168.42     Florida  166187.94\n"
     ]
    }
   ],
   "source": [
    "# load the data as a dataframe\n",
    "df = pd.read_csv('data/50_Startups.csv')\n",
    "\n",
    "# inspect shape and first rows of data\n",
    "print(df.shape, '\\n', df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that Profit is our response variable, so let's look a little more at our features. W have:\n",
    "+ $x_{1}$ = R&D Spend\n",
    "+ $x_{2}$ = Administration\n",
    "+ $x_{3}$ = Marketing Spend\n",
    "+ $x_{4}$ = State\n",
    "\n",
    "We can see that the the first three features are pretty straight forward, but the State column is obviously categorical. This means we need to introduce dummy variables. For each category in the column we will create a new column. This implies our regression model will look more like:\n",
    "\n",
    "$\n",
    "y=b_{0}+b_{1}x_{1}+b_{2}x_{2}+b_{3}x_{3}+b_{4}D_{1}+\\ldots+b_{n+2}D_{n-1},\n",
    "$\n",
    "\n",
    "where $D_{1}$ is the first dummy variable and $n$ is the total number of categories required by that feature. Remember that, in order to avoid the dummy variable trap, we will want to ensure we have one less dummy variable than the total number of categories in our categorical feature (hence $n-1$). Note that the $n+2$ takes into account, not only the one less dummy variable, but also $b_{1}$, $b_{2}$, and $b_{3}$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How To Build A Model With More Than One Feature\n",
    "\n",
    "Since the this model has more than one feature, we must consider the features before cramming them into an algorithm and demand it build us an army worthy of Mordor. We have to actually *build* the model by analyzing the features and selecting which ones are best to include in the model. This is because all the features are potential predictors of the response variable and, according to the garbage in, garbage out principle, if some of the predictors are garbage and we include them, our model will give us garbage. Another reason is that, when it comes to explaining our model to someone who doesn't have the knowledge we do in our field (like a client), it is easier to explain if we don't have a thousand predictors to talk about.\n",
    "\n",
    "There are a number of different ways to do this. We could use:\n",
    "\n",
    "+ Use them all\n",
    "+ Backward elimination\n",
    "+ Forward selection\n",
    "+ Bidirectional elimination\n",
    "+ Score comparison\n",
    "\n",
    "Each has it's own ups and downs. Let's get a little information on these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use 'Em All\n",
    "\n",
    "Basically, use every single one of the features in the model. Not recommended, but if you have knowledge about the features and know that they all belong in the model, go for it. Otherwise, do this if you just have to, like if you are told to by \"the boss,\" or is just a part of the biz.\n",
    "\n",
    "There is another reason to do this: when you're preparing for the backward elimination strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward Elimination\n",
    "\n",
    "This is where we take a significance level (like, say, 0.05) that will be the threshold for keeping features in the model. Then, taking all the features, fit the model. Once the model has been fitted, consider predictor with the highest *p-value* and if it is higher than you're significance level, drop it. Next, fit the model again, without that feature. Rinse and repeat with the next feature that has the highest *p-value*. When there ain't no more feature with *p-value* greater than your significance level, there you go."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Selection\n",
    "\n",
    "In forward selection, we select a significance level to *enter* the model, then fit a simple regression model with *every single feature* independently. When we have done this, we keep only the one feature that has the lowest *p-value*. Now, we fit all possible models with that feature *and* one additional feature, for each other feature. Consider the one variable that has the lowest *p-value* that was not the the kept before with the intention of continuing this process. building the model one variable at a time. We call it quits when we no longer have a feature whose *p-value* is less than our significance level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional Elimination\n",
    "\n",
    "This is, in essence, a combination of backward elimination and forward selection. We start by setting a significance level for entering the model and another for dropping out of the model. The we kick off with fitting a simple regression model with each feature, noting that new features must have a *p-value* greater than our entry significance level. Next we perform all the steps involved in backward elimination, noting that features will get dropped if their *p-value* is less then the siginificance level required to stay in the model. Keep doing this until no new features can be added *and* no old features can be kicked out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score Comparison\n",
    "\n",
    "This one is interesting. It the most resource consuming in that we consider all possible regression models and select the best one based on a set of criterion I call the \"the special goodness.\" Understand that the the claim that this is resource intensive is because trying out all possible regression models is a combination problem. As in all possible models is $2^{N}-1$ models. To put that in perspective, if you have a data set with 14 feature variables, you then have 16,383 possible regression models to try."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have some plans on how to treat the data, let's get to it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the data into response and feature dataframes\n",
    "X = df.iloc[:,:-1].values\n",
    "y = df.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X\n",
      " [[165349.2 136897.8 471784.1 'New York']\n",
      " [162597.7 151377.59 443898.53 'California']\n",
      " [153441.51 101145.55 407934.54 'Florida']\n",
      " [144372.41 118671.85 383199.62 'New York']\n",
      " [142107.34 91391.77 366168.42 'Florida']\n",
      " [131876.9 99814.71 362861.36 'New York']\n",
      " [134615.46 147198.87 127716.82 'California']\n",
      " [130298.13 145530.06 323876.68 'Florida']\n",
      " [120542.52 148718.95 311613.29 'New York']\n",
      " [123334.88 108679.17 304981.62 'California']\n",
      " [101913.08 110594.11 229160.95 'Florida']\n",
      " [100671.96 91790.61 249744.55 'California']\n",
      " [93863.75 127320.38 249839.44 'Florida']\n",
      " [91992.39 135495.07 252664.93 'California']\n",
      " [119943.24 156547.42 256512.92 'Florida']\n",
      " [114523.61 122616.84 261776.23 'New York']\n",
      " [78013.11 121597.55 264346.06 'California']\n",
      " [94657.16 145077.58 282574.31 'New York']\n",
      " [91749.16 114175.79 294919.57 'Florida']\n",
      " [86419.7 153514.11 0.0 'New York']\n",
      " [76253.86 113867.3 298664.47 'California']\n",
      " [78389.47 153773.43 299737.29 'New York']\n",
      " [73994.56 122782.75 303319.26 'Florida']\n",
      " [67532.53 105751.03 304768.73 'Florida']\n",
      " [77044.01 99281.34 140574.81 'New York']\n",
      " [64664.71 139553.16 137962.62 'California']\n",
      " [75328.87 144135.98 134050.07 'Florida']\n",
      " [72107.6 127864.55 353183.81 'New York']\n",
      " [66051.52 182645.56 118148.2 'Florida']\n",
      " [65605.48 153032.06 107138.38 'New York']\n",
      " [61994.48 115641.28 91131.24 'Florida']\n",
      " [61136.38 152701.92 88218.23 'New York']\n",
      " [63408.86 129219.61 46085.25 'California']\n",
      " [55493.95 103057.49 214634.81 'Florida']\n",
      " [46426.07 157693.92 210797.67 'California']\n",
      " [46014.02 85047.44 205517.64 'New York']\n",
      " [28663.76 127056.21 201126.82 'Florida']\n",
      " [44069.95 51283.14 197029.42 'California']\n",
      " [20229.59 65947.93 185265.1 'New York']\n",
      " [38558.51 82982.09 174999.3 'California']\n",
      " [28754.33 118546.05 172795.67 'California']\n",
      " [27892.92 84710.77 164470.71 'Florida']\n",
      " [23640.93 96189.63 148001.11 'California']\n",
      " [15505.73 127382.3 35534.17 'New York']\n",
      " [22177.74 154806.14 28334.72 'California']\n",
      " [1000.23 124153.04 1903.93 'New York']\n",
      " [1315.46 115816.21 297114.46 'Florida']\n",
      " [0.0 135426.92 0.0 'California']\n",
      " [542.05 51743.15 0.0 'New York']\n",
      " [0.0 116983.8 45173.06 'California']] \n",
      " y\n",
      " [192261.83 191792.06 191050.39 182901.99 166187.94 156991.12 156122.51\n",
      " 155752.6  152211.77 149759.96 146121.95 144259.4  141585.52 134307.35\n",
      " 132602.65 129917.04 126992.93 125370.37 124266.9  122776.86 118474.03\n",
      " 111313.02 110352.25 108733.99 108552.04 107404.34 105733.54 105008.31\n",
      " 103282.38 101004.64  99937.59  97483.56  97427.84  96778.92  96712.8\n",
      "  96479.51  90708.19  89949.14  81229.06  81005.76  78239.91  77798.83\n",
      "  71498.49  69758.98  65200.33  64926.08  49490.75  42559.73  35673.41\n",
      "  14681.4 ]\n"
     ]
    }
   ],
   "source": [
    "# inspect these matrices\n",
    "print('X\\n', X, '\\n', 'y\\n', y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's encode that State column with our One Hot Encoding!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding the categorical feature\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# the encoding\n",
    "labelencoder_X = LabelEncoder()\n",
    "X[:,-1] = labelencoder_X.fit_transform(X[:,-1]) \n",
    "\n",
    "onehotencoder = OneHotEncoder(categorical_features=[3])\n",
    "X = onehotencoder.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1    2          3          4          5\n",
      "0  0.0  0.0  1.0  165349.20  136897.80  471784.10\n",
      "1  1.0  0.0  0.0  162597.70  151377.59  443898.53\n",
      "2  0.0  1.0  0.0  153441.51  101145.55  407934.54\n",
      "3  0.0  0.0  1.0  144372.41  118671.85  383199.62\n",
      "4  0.0  1.0  0.0  142107.34   91391.77  366168.42\n"
     ]
    }
   ],
   "source": [
    "# inspect encoding of categorical feature\n",
    "print(pd.DataFrame(X).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent. But now that we have this encoded properly, let's make sure we avoind the dummy variable trap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avoid dummy variable trap\n",
    "X = X[:,1:]  # simply remove the first column of the features data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into traiinng and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X\n",
      " [[1.0000000e+00 0.0000000e+00 5.5493950e+04 1.0305749e+05 2.1463481e+05]\n",
      " [0.0000000e+00 1.0000000e+00 4.6014020e+04 8.5047440e+04 2.0551764e+05]\n",
      " [1.0000000e+00 0.0000000e+00 7.5328870e+04 1.4413598e+05 1.3405007e+05]\n",
      " [0.0000000e+00 0.0000000e+00 4.6426070e+04 1.5769392e+05 2.1079767e+05]\n",
      " [1.0000000e+00 0.0000000e+00 9.1749160e+04 1.1417579e+05 2.9491957e+05]\n",
      " [1.0000000e+00 0.0000000e+00 1.3029813e+05 1.4553006e+05 3.2387668e+05]\n",
      " [1.0000000e+00 0.0000000e+00 1.1994324e+05 1.5654742e+05 2.5651292e+05]\n",
      " [0.0000000e+00 1.0000000e+00 1.0002300e+03 1.2415304e+05 1.9039300e+03]\n",
      " [0.0000000e+00 1.0000000e+00 5.4205000e+02 5.1743150e+04 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 6.5605480e+04 1.5303206e+05 1.0713838e+05]\n",
      " [0.0000000e+00 1.0000000e+00 1.1452361e+05 1.2261684e+05 2.6177623e+05]\n",
      " [1.0000000e+00 0.0000000e+00 6.1994480e+04 1.1564128e+05 9.1131240e+04]\n",
      " [0.0000000e+00 0.0000000e+00 6.3408860e+04 1.2921961e+05 4.6085250e+04]\n",
      " [0.0000000e+00 0.0000000e+00 7.8013110e+04 1.2159755e+05 2.6434606e+05]\n",
      " [0.0000000e+00 0.0000000e+00 2.3640930e+04 9.6189630e+04 1.4800111e+05]\n",
      " [0.0000000e+00 0.0000000e+00 7.6253860e+04 1.1386730e+05 2.9866447e+05]\n",
      " [0.0000000e+00 1.0000000e+00 1.5505730e+04 1.2738230e+05 3.5534170e+04]\n",
      " [0.0000000e+00 1.0000000e+00 1.2054252e+05 1.4871895e+05 3.1161329e+05]\n",
      " [0.0000000e+00 0.0000000e+00 9.1992390e+04 1.3549507e+05 2.5266493e+05]\n",
      " [0.0000000e+00 0.0000000e+00 6.4664710e+04 1.3955316e+05 1.3796262e+05]\n",
      " [0.0000000e+00 1.0000000e+00 1.3187690e+05 9.9814710e+04 3.6286136e+05]\n",
      " [0.0000000e+00 1.0000000e+00 9.4657160e+04 1.4507758e+05 2.8257431e+05]\n",
      " [0.0000000e+00 0.0000000e+00 2.8754330e+04 1.1854605e+05 1.7279567e+05]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 1.1698380e+05 4.5173060e+04]\n",
      " [0.0000000e+00 0.0000000e+00 1.6259770e+05 1.5137759e+05 4.4389853e+05]\n",
      " [1.0000000e+00 0.0000000e+00 9.3863750e+04 1.2732038e+05 2.4983944e+05]\n",
      " [0.0000000e+00 0.0000000e+00 4.4069950e+04 5.1283140e+04 1.9702942e+05]\n",
      " [0.0000000e+00 1.0000000e+00 7.7044010e+04 9.9281340e+04 1.4057481e+05]\n",
      " [0.0000000e+00 0.0000000e+00 1.3461546e+05 1.4719887e+05 1.2771682e+05]\n",
      " [1.0000000e+00 0.0000000e+00 6.7532530e+04 1.0575103e+05 3.0476873e+05]\n",
      " [1.0000000e+00 0.0000000e+00 2.8663760e+04 1.2705621e+05 2.0112682e+05]\n",
      " [0.0000000e+00 1.0000000e+00 7.8389470e+04 1.5377343e+05 2.9973729e+05]\n",
      " [0.0000000e+00 1.0000000e+00 8.6419700e+04 1.5351411e+05 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.2333488e+05 1.0867917e+05 3.0498162e+05]\n",
      " [0.0000000e+00 0.0000000e+00 3.8558510e+04 8.2982090e+04 1.7499930e+05]\n",
      " [1.0000000e+00 0.0000000e+00 1.3154600e+03 1.1581621e+05 2.9711446e+05]\n",
      " [0.0000000e+00 1.0000000e+00 1.4437241e+05 1.1867185e+05 3.8319962e+05]\n",
      " [0.0000000e+00 1.0000000e+00 1.6534920e+05 1.3689780e+05 4.7178410e+05]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 1.3542692e+05 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 2.2177740e+04 1.5480614e+05 2.8334720e+04]] \n",
      " y\n",
      " [ 96778.92  96479.51 105733.54  96712.8  124266.9  155752.6  132602.65\n",
      "  64926.08  35673.41 101004.64 129917.04  99937.59  97427.84 126992.93\n",
      "  71498.49 118474.03  69758.98 152211.77 134307.35 107404.34 156991.12\n",
      " 125370.37  78239.91  14681.4  191792.06 141585.52  89949.14 108552.04\n",
      " 156122.51 108733.99  90708.19 111313.02 122776.86 149759.96  81005.76\n",
      "  49490.75 182901.99 192261.83  42559.73  65200.33]\n"
     ]
    }
   ],
   "source": [
    "# inspect the training set\n",
    "print('X\\n', X_train, '\\n', 'y\\n', y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X\n",
      " [[1.0000000e+00 0.0000000e+00 6.6051520e+04 1.8264556e+05 1.1814820e+05]\n",
      " [0.0000000e+00 0.0000000e+00 1.0067196e+05 9.1790610e+04 2.4974455e+05]\n",
      " [1.0000000e+00 0.0000000e+00 1.0191308e+05 1.1059411e+05 2.2916095e+05]\n",
      " [1.0000000e+00 0.0000000e+00 2.7892920e+04 8.4710770e+04 1.6447071e+05]\n",
      " [1.0000000e+00 0.0000000e+00 1.5344151e+05 1.0114555e+05 4.0793454e+05]\n",
      " [0.0000000e+00 1.0000000e+00 7.2107600e+04 1.2786455e+05 3.5318381e+05]\n",
      " [0.0000000e+00 1.0000000e+00 2.0229590e+04 6.5947930e+04 1.8526510e+05]\n",
      " [0.0000000e+00 1.0000000e+00 6.1136380e+04 1.5270192e+05 8.8218230e+04]\n",
      " [1.0000000e+00 0.0000000e+00 7.3994560e+04 1.2278275e+05 3.0331926e+05]\n",
      " [1.0000000e+00 0.0000000e+00 1.4210734e+05 9.1391770e+04 3.6616842e+05]] \n",
      " y\n",
      " [103282.38 144259.4  146121.95  77798.83 191050.39 105008.31  81229.06\n",
      "  97483.56 110352.25 166187.94]\n"
     ]
    }
   ],
   "source": [
    "# inspect the test set\n",
    "print('X\\n', X_test, '\\n', 'y\\n', y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have created the training and test sets, it's time to...\n",
    "\n",
    "## Fit The Model\n",
    "\n",
    "Recall from above that there are some startegies for building the model with choosing the best features. We will run through this with choosing:\n",
    "\n",
    "### All The Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the multiple linear regression model to the training set\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has been fit to the training set which leaves us with testing the model's peformance. Let's do it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Model Performance\n",
    "\n",
    "We will create the vector of predictions. This is the vector populated with predictions of our test set, made by the model we just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediciting test observations\n",
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********Test & Predicted********\n",
      " [[103282.38       103015.20159796]\n",
      " [144259.4        132582.27760815]\n",
      " [146121.95       132447.73845175]\n",
      " [ 77798.83        71976.09851258]\n",
      " [191050.39       178537.48221056]\n",
      " [105008.31       116161.24230166]\n",
      " [ 81229.06        67851.69209676]\n",
      " [ 97483.56        98791.73374687]\n",
      " [110352.25       113969.43533013]\n",
      " [166187.94       167921.06569551]]\n"
     ]
    }
   ],
   "source": [
    "# inspect the predicted observation and the actual observations\n",
    "y_test_show = np.array(y_test)\n",
    "y_pred_show = np.array(y_pred)\n",
    "y_show = np.column_stack((y_test_show,y_pred_show))\n",
    "\n",
    "print('********Test & Predicted********\\n',y_show)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not too shabby!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that was when we choose all the features to build the model. What happens if we decided to use:\n",
    "\n",
    "### Backward Elimination\n",
    "\n",
    "Since not everyone is a fan of reinventing the wheel when we just need to get the damn thing done, we will call upon the Stasmodel package to help us out with this. Otherwise, could implement it ourselves, which is always an option, especially if you wish to fine tune it, or you have a different implementation strategy. You do you!\n",
    "\n",
    "One thing about this package though, it does not include the $b_{0}$ constant that our model requires. We will need to take care of that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the statsmodels package\n",
    "import statsmodels.formula.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column of ones that corresponds to the b_0 constant\n",
    "X = np.append(arr=np.ones((50,1)).astype(int), values=X, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1    2          3          4          5\n",
      "0  1.0  0.0  1.0  165349.20  136897.80  471784.10\n",
      "1  1.0  0.0  0.0  162597.70  151377.59  443898.53\n",
      "2  1.0  1.0  0.0  153441.51  101145.55  407934.54\n",
      "3  1.0  0.0  1.0  144372.41  118671.85  383199.62\n",
      "4  1.0  1.0  0.0  142107.34   91391.77  366168.42\n"
     ]
    }
   ],
   "source": [
    "# inspect the X array to ensure we did that column add correctly\n",
    "print(pd.DataFrame(X).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new matrix of feature choosing them with backward elimination\n",
    "# columns explicitely called so we can \"see\" what we're removing as we build\n",
    "X_optimal = X[:,[0,1,2,3,4,5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new regressor, ordinary least squares: regressor_OLS\n",
    "regressor_OLS = sm.OLS(endog=y, exog=X_optimal).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.951\n",
      "Model:                            OLS   Adj. R-squared:                  0.945\n",
      "Method:                 Least Squares   F-statistic:                     169.9\n",
      "Date:                Fri, 13 Jul 2018   Prob (F-statistic):           1.34e-27\n",
      "Time:                        22:52:12   Log-Likelihood:                -525.38\n",
      "No. Observations:                  50   AIC:                             1063.\n",
      "Df Residuals:                      44   BIC:                             1074.\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       5.013e+04   6884.820      7.281      0.000    3.62e+04     6.4e+04\n",
      "x1           198.7888   3371.007      0.059      0.953   -6595.030    6992.607\n",
      "x2           -41.8870   3256.039     -0.013      0.990   -6604.003    6520.229\n",
      "x3             0.8060      0.046     17.369      0.000       0.712       0.900\n",
      "x4            -0.0270      0.052     -0.517      0.608      -0.132       0.078\n",
      "x5             0.0270      0.017      1.574      0.123      -0.008       0.062\n",
      "==============================================================================\n",
      "Omnibus:                       14.782   Durbin-Watson:                   1.283\n",
      "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.266\n",
      "Skew:                          -0.948   Prob(JB):                     2.41e-05\n",
      "Kurtosis:                       5.572   Cond. No.                     1.45e+06\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.45e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# use summary function from statsmodels to compare the p-values of the features in the trained model\n",
    "print(regressor_OLS.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " So we are seeing the *p-values* of the features in the model. As we can see, the $x_{2}$ variable is *way* above the 0.05 siginificance level we cited in the explanation above. We need to let it go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.951\n",
      "Model:                            OLS   Adj. R-squared:                  0.946\n",
      "Method:                 Least Squares   F-statistic:                     217.2\n",
      "Date:                Fri, 13 Jul 2018   Prob (F-statistic):           8.49e-29\n",
      "Time:                        22:52:12   Log-Likelihood:                -525.38\n",
      "No. Observations:                  50   AIC:                             1061.\n",
      "Df Residuals:                      45   BIC:                             1070.\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       5.011e+04   6647.870      7.537      0.000    3.67e+04    6.35e+04\n",
      "x1           220.1585   2900.536      0.076      0.940   -5621.821    6062.138\n",
      "x2             0.8060      0.046     17.606      0.000       0.714       0.898\n",
      "x3            -0.0270      0.052     -0.523      0.604      -0.131       0.077\n",
      "x4             0.0270      0.017      1.592      0.118      -0.007       0.061\n",
      "==============================================================================\n",
      "Omnibus:                       14.758   Durbin-Watson:                   1.282\n",
      "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.172\n",
      "Skew:                          -0.948   Prob(JB):                     2.53e-05\n",
      "Kurtosis:                       5.563   Cond. No.                     1.40e+06\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.4e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# matrix of feature choosing them with backward elimination\n",
    "# columns explicitely called so we can \"see\" what we're removing as we build\n",
    "X_optimal = X[:,[0,1,3,4,5]]\n",
    "\n",
    "# create new regressor, ordinary least squares: regressor_OLS\n",
    "regressor_OLS = sm.OLS(endog=y, exog=X_optimal).fit()\n",
    "\n",
    "# use summary function from statsmodels to compare the p-values of the features in the trained model\n",
    "print(regressor_OLS.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cut $x_{1}$!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.951\n",
      "Model:                            OLS   Adj. R-squared:                  0.948\n",
      "Method:                 Least Squares   F-statistic:                     296.0\n",
      "Date:                Fri, 13 Jul 2018   Prob (F-statistic):           4.53e-30\n",
      "Time:                        22:52:12   Log-Likelihood:                -525.39\n",
      "No. Observations:                  50   AIC:                             1059.\n",
      "Df Residuals:                      46   BIC:                             1066.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       5.012e+04   6572.353      7.626      0.000    3.69e+04    6.34e+04\n",
      "x1             0.8057      0.045     17.846      0.000       0.715       0.897\n",
      "x2            -0.0268      0.051     -0.526      0.602      -0.130       0.076\n",
      "x3             0.0272      0.016      1.655      0.105      -0.006       0.060\n",
      "==============================================================================\n",
      "Omnibus:                       14.838   Durbin-Watson:                   1.282\n",
      "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.442\n",
      "Skew:                          -0.949   Prob(JB):                     2.21e-05\n",
      "Kurtosis:                       5.586   Cond. No.                     1.40e+06\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.4e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# matrix of feature choosing them with backward elimination\n",
    "# columns explicitely called so we can \"see\" what we're removing as we build\n",
    "X_optimal = X[:,[0,3,4,5]]\n",
    "\n",
    "# create new regressor, ordinary least squares: regressor_OLS\n",
    "regressor_OLS = sm.OLS(endog=y, exog=X_optimal).fit()\n",
    "\n",
    "# use summary function from statsmodels to compare the p-values of the features in the trained model\n",
    "print(regressor_OLS.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And out with the $x_{2}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.950\n",
      "Model:                            OLS   Adj. R-squared:                  0.948\n",
      "Method:                 Least Squares   F-statistic:                     450.8\n",
      "Date:                Fri, 13 Jul 2018   Prob (F-statistic):           2.16e-31\n",
      "Time:                        22:52:12   Log-Likelihood:                -525.54\n",
      "No. Observations:                  50   AIC:                             1057.\n",
      "Df Residuals:                      47   BIC:                             1063.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       4.698e+04   2689.933     17.464      0.000    4.16e+04    5.24e+04\n",
      "x1             0.7966      0.041     19.266      0.000       0.713       0.880\n",
      "x2             0.0299      0.016      1.927      0.060      -0.001       0.061\n",
      "==============================================================================\n",
      "Omnibus:                       14.677   Durbin-Watson:                   1.257\n",
      "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.161\n",
      "Skew:                          -0.939   Prob(JB):                     2.54e-05\n",
      "Kurtosis:                       5.575   Cond. No.                     5.32e+05\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 5.32e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# matrix of feature choosing them with backward elimination\n",
    "# columns explicitely called so we can \"see\" what we're removing as we build\n",
    "X_optimal = X[:,[0,3,5]]\n",
    "\n",
    "# create new regressor, ordinary least squares: regressor_OLS\n",
    "regressor_OLS = sm.OLS(endog=y, exog=X_optimal).fit()\n",
    "\n",
    "# use summary function from statsmodels to compare the p-values of the features in the trained model\n",
    "print(regressor_OLS.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, let's slow down here. We have used backward elimination to eliminate all features except for two. As you can see in the table above, the last feature has a $p-value$ that is slightly above the significance level of 0.05, which means we drop it like it's hot, according to the process. This may not end up being the optimal model we are about to make if we cut it. We will explore another feature selection startegy that may end up keeping more than just a single feature, but for the sake of this demonstration, we will follow the algorithm and cut it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.947\n",
      "Model:                            OLS   Adj. R-squared:                  0.945\n",
      "Method:                 Least Squares   F-statistic:                     849.8\n",
      "Date:                Fri, 13 Jul 2018   Prob (F-statistic):           3.50e-32\n",
      "Time:                        22:52:12   Log-Likelihood:                -527.44\n",
      "No. Observations:                  50   AIC:                             1059.\n",
      "Df Residuals:                      48   BIC:                             1063.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       4.903e+04   2537.897     19.320      0.000    4.39e+04    5.41e+04\n",
      "x1             0.8543      0.029     29.151      0.000       0.795       0.913\n",
      "==============================================================================\n",
      "Omnibus:                       13.727   Durbin-Watson:                   1.116\n",
      "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               18.536\n",
      "Skew:                          -0.911   Prob(JB):                     9.44e-05\n",
      "Kurtosis:                       5.361   Cond. No.                     1.65e+05\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.65e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# matrix of feature choosing them with backward elimination\n",
    "# columns explicitely called so we can \"see\" what we're removing as we build\n",
    "X_optimal = X[:,[0,3]]\n",
    "\n",
    "# create new regressor, ordinary least squares: regressor_OLS\n",
    "regressor_OLS = sm.OLS(endog=y, exog=X_optimal).fit()\n",
    "\n",
    "# use summary function from statsmodels to compare the p-values of the features in the trained model\n",
    "print(regressor_OLS.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the backward elimination strategy, the feature, $x_{1}$, or R&D Spending, is a huge predictor of Profit! If we built the model with that as the feature, we might end up with an optimal model. But I suggest you try another strategy first to be sure. Have fun!\n",
    "\n",
    "As a bonus, here is script, from Hadelin de Ponteves, that automatically handles backward elimination using a significance level of 0.05, *and* the adjusted R-squared value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import statsmodels.formula.api as sm\n",
    "#def backwardElimination(x, SL):\n",
    "#    numVars = len(x[0])\n",
    "#    temp = np.zeros((50,6)).astype(int)\n",
    "#    for i in range(0, numVars):\n",
    "#        regressor_OLS = sm.OLS(y, x).fit()\n",
    "#        maxVar = max(regressor_OLS.pvalues).astype(float)\n",
    "#        adjR_before = regressor_OLS.rsquared_adj.astype(float)\n",
    "#        if maxVar > SL:\n",
    "#            for j in range(0, numVars - i):\n",
    "#                    temp[:,j] = x[:, j]\n",
    "#                    x = np.delete(x, j, 1)\n",
    "#                    tmp_regressor = sm.OLS(y, x).fit()\n",
    "#                    adjR_after = tmp_regressor.rsquared_adj.astype(float)\n",
    "#                    if (adjR_before >= adjR_after):\n",
    "#                        x_rollback = np.hstack((x, temp[:,[0,j]]))\n",
    "#                        x_rollback = np.delete(x_rollback, j, 1)\n",
    "#                        print (regressor_OLS.summary())\n",
    "#                        return x_rollback\n",
    "#                    else:\n",
    "#                        continue\n",
    "#    regressor_OLS.summary()\n",
    "#    return x\n",
    "# \n",
    "#SL = 0.05\n",
    "#X_optimal = X[:, [0, 1, 2, 3, 4, 5]]\n",
    "#X_Modeled = backwardElimination(X_opt, SL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
