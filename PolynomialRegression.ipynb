{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial Linear Regression\n",
    "\n",
    "In keeping with the idea of the linear regression, we still have a response variable that has some dependency on a predictor variable. The exception is with the Polynomial Regression, as the name implies, is with the relationship between the response variable and the predictors is that rather than having  just the $b_{1}x_{1}$ term, we have a polynomial (different powers of $x_{1}$:\n",
    "\n",
    "$\n",
    "y=b_{0}+b_{1}x_{1}+b_{2}x_{1}^{2}+\\ldots+b_{n}x_{1}^{n}\n",
    "$\n",
    "\n",
    "An imminent question regarding the flavor of regression this falls under is \"how is this a *linear* regression model if the dependency is of polynomial order?\" A fine question indeed. Linear regression models are not referred to as \"linear\" based on their order of dependent variables; rather, they are refering to the *coefficients*, $b$. Yes, $y$ is a function of $x$, but the question is \"can y be expressed as a *linear combination of the coefficients*? This makes as these are the real unknowns in machine learning (think about it, we know the $x$'s: they're in our data sets!). Once we know the coefficients, we can then plug in the $x$'s and predict the response, $y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Business Understanding and The Data\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
